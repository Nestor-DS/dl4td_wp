{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary functions from custom modules\n",
    "from modules.data_preparation import data_to_image, data_to_heatmap_bw   # Function to convert data to images\n",
    "from modules.model import model_res                  # Pre-defined model architecture\n",
    "from modules.train import train_model                # Function to train the model\n",
    "from modules.data_cleaning import clean_data         # Function to clean and preprocess data\n",
    "from modules.basics import *                         # Other utility functions\n",
    "\n",
    "# Disabling cudnn for deterministic results\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "# Selecting the device for training (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Loading the autoreload extension to automatically reload modules\n",
    "%load_ext autoreload\n",
    "\n",
    "# Setting autoreload to automatically reload all modules\n",
    "%autoreload 2\n",
    "\n",
    "# Setting matplotlib to display plots inline in the Jupyter Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Setting the figure format for inline plotting to 'retina' for better quality\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/drinking_water_potability.csv')\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza y normalización de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = clean_data(df)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Potability', data=df_cleaned)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanceo de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Selecting features (independent variables) and the target variable (dependent variable)\n",
    "features = df_cleaned.drop('Potability', axis=1)\n",
    "labels = df_cleaned['Potability']\n",
    "\n",
    "# Creating arrays for features and labels\n",
    "features_space = features\n",
    "labels_space = labels.values\n",
    "\n",
    "# Selecting 200 random samples from the dataset\n",
    "random_values = features_space.sample(n=100)\n",
    "X_sample = random_values.values\n",
    "y_sample = labels_space[random_values.index]\n",
    "\n",
    "# Instantiating the RandomOverSampler with random_state=0\n",
    "oversampler = RandomOverSampler(random_state=0)\n",
    "\n",
    "# Performing random oversampling to balance the dataset\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X_sample, y_sample)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importar RandomOverSampler de la biblioteca imbalanced-learn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Seleccionar características (variables independientes) y la variable objetivo (variable dependiente)\n",
    "features = df_cleaned.drop('Potability', axis=1)\n",
    "labels = df_cleaned['Potability']\n",
    "\n",
    "# Crear arrays para características y etiquetas\n",
    "features_space = features.values\n",
    "labels_space = labels.values\n",
    "\n",
    "# Instanciar el RandomOverSampler con random_state=0\n",
    "oversampler = RandomOverSampler(random_state=0)\n",
    "\n",
    "# Realizar el sobremuestreo aleatorio para equilibrar el conjunto de datos completo\n",
    "X_resampled, y_resampled = oversampler.fit_resample(features_space, labels_space)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the values in X_resampled to 2 decimal places\n",
    "X_resampled_rounded = np.round(X_resampled, 2)\n",
    "\n",
    "# Splitting the rounded data into training and validation sets\n",
    "# test_size=0.2 specifies that 20% of the data will be used for validation\n",
    "# random_state=42 sets the random seed for reproducibility\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled_rounded, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Printing the shapes of the training and validation sets\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the numerical training data into images\n",
    "train_images = data_to_image(X_train)\n",
    "\n",
    "# Converting the numerical validation data into images\n",
    "val_images = data_to_image(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crear una carpeta para guardar las imágenes si no existe\n",
    "if not os.path.exists('images_saved'):\n",
    "    os.makedirs('images_saved')\n",
    "\n",
    "# Iterar sobre el índice de las imágenes\n",
    "for i in range(len(train_images)):\n",
    "    # Mostrar y guardar la imagen actual\n",
    "    plt.imshow(train_images[i][0, :, :])\n",
    "    plt.savefig(f'images_saved/stml_{i}.png')\n",
    "    plt.close()  # Cerrar la figura para evitar que se superpongan las imágenes\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_images.shape)\n",
    "print(val_images.shape)\n",
    "plt.grid()\n",
    "plt.imshow(train_images[12][0, :, :])\n",
    "\n",
    "plt.savefig('imagen_guardada.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the training images to PyTorch tensors\n",
    "X_train_I = torch.from_numpy(train_images).float()\n",
    "\n",
    "# Converting the training labels to PyTorch tensors\n",
    "y_train_I = torch.from_numpy(y_train).long()\n",
    "\n",
    "# Converting the validation images to PyTorch tensors\n",
    "X_val_I = torch.from_numpy(val_images).float()\n",
    "\n",
    "# Converting the validation labels to PyTorch tensors\n",
    "y_val_I = torch.from_numpy(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PyTorch datasets for training and validation\n",
    "train_dataset = TensorDataset(X_train_I, y_train_I)\n",
    "val_dataset = TensorDataset(X_val_I, y_val_I)\n",
    "\n",
    "# Creating data loaders for training and validation sets\n",
    "# The DataLoader class provides an iterable over the dataset, with optional shuffling and batching\n",
    "dataloaders = {'train': DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
    "               'val': DataLoader(val_dataset)}\n",
    "\n",
    "# Storing the sizes of the training and validation datasets\n",
    "dataset_sizes = {'train': len(X_train),\n",
    "                 'val': len(X_val)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: By [AHN MINJAE](https://github.com/EmjayAhn/SuperTML-pytorch)\n",
    "- Transfer Learning from Resnet\n",
    "- I changed just fully connect layer at the end to 3 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the pre-defined model to the specified device (GPU if available, otherwise CPU)\n",
    "model = model_res.to(device)\n",
    "\n",
    "# Defining the loss function (cross-entropy loss)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Defining the optimizer (Adam optimizer) and passing model parameters to be optimized\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = train_model(model, dataloaders, dataset_sizes, criterion, optimizer, device, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Hdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir los datos a mapas de calor en escala de grises\n",
    "train_heatmaps_bw = data_to_heatmap_bw(X_train)\n",
    "val_heatmaps_bw = data_to_heatmap_bw(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Forma de train_heatmaps_bw:', train_heatmaps_bw.shape)\n",
    "print('Forma de val_heatmaps_bw:', val_heatmaps_bw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the training images to PyTorch tensors\n",
    "X_train_II = torch.from_numpy(train_heatmaps_bw).float()\n",
    "\n",
    "# Converting the training labels to PyTorch tensors\n",
    "y_train_II = torch.from_numpy(y_train).long()\n",
    "\n",
    "# Converting the validation images to PyTorch tensors\n",
    "X_val_II = torch.from_numpy(val_heatmaps_bw).float()\n",
    "\n",
    "# Converting the validation labels to PyTorch tensors\n",
    "y_val_II = torch.from_numpy(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_II = torch.from_numpy(train_heatmaps_bw).float()\n",
    "X_val_II = torch.from_numpy(val_heatmaps_bw).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_heatmaps_bw = np.mean(train_heatmaps_bw, axis=3)\n",
    "val_heatmaps_bw = np.mean(val_heatmaps_bw, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tamaño de X_train_II - batch_size:', X_train_II.size(0))\n",
    "print('Tamaño de X_train_II - canales:', X_train_II.size(1))\n",
    "print('Tamaño de X_train_II - altura:', X_train_II.size(2))\n",
    "print('Tamaño de X_train_II - ancho:', X_train_II.size(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.  Preparar los datos para PyTorch:** Convierte los mapas de calor a tensores de PyTorch y crea conjuntos de datos y cargadores de datos para el entrenamiento y la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Convertir los mapas de calor a tensores de PyTorch\n",
    "X_train_tensor = torch.from_numpy(train_heatmaps_bw).unsqueeze(1).float()\n",
    "X_val_tensor = torch.from_numpy(val_heatmaps_bw).unsqueeze(1).float()\n",
    "\n",
    "# Crear conjuntos de datos y cargadores de datos\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_II)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_II)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Definir el modelo CNN:** Define la arquitectura de tu modelo CNN en PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Definir las capas convolucionales y de pooling\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        # Definir las capas completamente conectadas\n",
    "        self.fc1 = nn.Linear(32 * 120 * 160, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)  # 2 clases (potable, no potable)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Aplicar convoluciones y funciones de activación\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Aplanar la salida de las capas convolucionales\n",
    "        x = x.view(-1, 32 * 120 * 160)\n",
    "        # Aplicar capas completamente conectadas\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Entrenar el modelo:** Entrena el modelo utilizando los conjuntos de datos y cargadores de datos que has creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # Importa el módulo time\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Supongo que model, train_loader, y val_loader ya están definidos\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 20\n",
    "best_val_accuracy = 0.0  # Variable para rastrear el mejor rendimiento de validación\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()  # Inicia el contador de tiempo al inicio de la época\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    # Validación del modelo\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    epoch_time = time.time() - start_time  # Calcula el tiempo transcurrido al final de la época\n",
    "\n",
    "    print(f'EPOCH {epoch+1}/{epochs}:')\n",
    "    print('-' * 10)\n",
    "    print(f'Train Loss: {train_loss:.4f} Acc: {train_accuracy:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f} Acc: {val_accuracy:.4f}')\n",
    "    print(f'Epoch Time: {epoch_time:.2f} seconds\\n')  # Imprime el tiempo transcurrido\n",
    "\n",
    "    # Actualización del mejor rendimiento de validación\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "\n",
    "print(f'BEST VALIDATION ACCURACY: {best_val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model: RNN - En proceso :v (No sirve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Cambiar el tamaño de las imágenes a (224, 224)\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalización estándar\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = CustomDataset(X_val, y_val, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el extractor de características y el modelo ViT preentrenado\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)['logits']\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validación del modelo\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)['logits']\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Validation Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model T1**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images GG - ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión de datos a imágenes en escala de grises con 3 canales\n",
    "def gray_gang_gg(data):\n",
    "    cell_size = 85\n",
    "    rgb_images = []\n",
    "    for row in data:\n",
    "        image = np.zeros((255, 255, 3), dtype=np.uint8)\n",
    "        for i, value in enumerate(row):\n",
    "            x = (i % 3) * cell_size\n",
    "            y = (i // 3) * cell_size\n",
    "            grayscale_value = int(value * 255)\n",
    "            image[y:y+cell_size, x:x+cell_size] = [grayscale_value] * 3\n",
    "        rgb_images.append(image)\n",
    "    return np.array(rgb_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_gg = gray_gang_gg(X_train)\n",
    "val_images_gg = gray_gang_gg(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_images_gg[1]\n",
    "\n",
    "if isinstance(image, torch.Tensor):\n",
    "    image = image.numpy()\n",
    "\n",
    "if image.shape[0] == 3:  \n",
    "    image = np.transpose(image, (1, 3, 0))\n",
    "    \n",
    "plt.imshow(image)\n",
    "plt.title(\"Imagen número 2\")\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un Dataset personalizado para PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotabilityDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones para el dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PotabilityDataset(train_images_gg, y_train, transform=transform)\n",
    "val_dataset = PotabilityDataset(val_images_gg, y_val, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir y entrenar el modelo ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_accuracy = 0.0  # Variable para almacenar la mejor precisión de validación\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Train Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device, dtype=torch.long)\n",
    "                outputs = model(images).logits\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_accuracy = correct / total\n",
    "            print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "\n",
    "        print('-' * 10)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    print(f\"BEST VALIDATION ACCURACY: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images with PCA - ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Function\n",
    "def data_to_image_pca(data):\n",
    "    data_images = []\n",
    "    num_components = 3  # Number of principal components\n",
    "    pca = PCA(n_components=num_components)\n",
    "    data_pca = pca.fit_transform(data)\n",
    "\n",
    "    for dat in data_pca:\n",
    "        scaled_dat = ((dat - dat.min()) / (dat.max() - dat.min())) * 255\n",
    "        image = Image.new(\"RGB\", (255, 255))\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for i in range(len(scaled_dat)):\n",
    "            x = scaled_dat[i]\n",
    "            y = 150  # Adjust this vertical position as needed\n",
    "            draw.rectangle([x-1, y-1, x+1, y+1], fill='white')\n",
    "        data_images.append(np.array(image))\n",
    "    \n",
    "    return np.array(data_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = data_to_image_pca(X_train)\n",
    "val_images = data_to_image_pca(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotabilityDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PotabilityDataset(train_images, y_train, transform=transform)\n",
    "val_dataset = PotabilityDataset(val_images, y_val, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Assuming binary classification\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de transformers\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_1(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    best_val_accuracy = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"Train Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            val_accuracy = correct / total\n",
    "            print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "\n",
    "        print('-' * 10)\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "    print(f\"BEST VALIDATION ACCURACY: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_1(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = data_to_image_pca(X_train)\n",
    "val_images = data_to_image_pca(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotabilityDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  # ViT requires images of size 224x224\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = PotabilityDataset(train_images, y_train, transform=transform)\n",
    "val_dataset = PotabilityDataset(val_images, y_val, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', num_labels=2)  # Assuming binary classification\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_1(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
